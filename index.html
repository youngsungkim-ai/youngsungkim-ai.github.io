<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Youngsung Kim | AI Research Group</title>
  <meta content="AI Research Group at Inha University - Deep Learning, Computer Vision, Multimodal Learning" name="description">
  <meta content="artificial intelligence, deep learning, computer vision, multimodal learning, neurosymbolic AI, Faculty, University" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.ico" rel="icon">
  <link href="assets/img/favicon.ico" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="container">
      <h1><a href="index.html">Youngsung Kim's AI Research Group</a></h1>
      <h2>@ Inha University</h2>
      <h3><i class="bi bi-star"></i> Now Hiring: <span>Join Our Group</span></h3>

      
      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link active" href="#header">Home</a></li>
          <li><a class="nav-link" href="#about">About</a></li>
          <li><a class="nav-link" href="#interests">Research</a></li>
          <li><a class="nav-link" href="#publications">Publications</a></li>
          <li><a class="nav-link" href="#contact">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav>

      <div class="social-links">
        <a href="https://scholar.google.com/citations?user=A46lCAoAAAAJ&hl=en" target="_blank">
          <i class="bi bi-google"></i>
        </a>
        <a href="https://linkedin.com/in/youngsung-kim-156a4345" target="_blank">
          <i class="bi bi-linkedin"></i>
        </a>
        <!--<a href="https://github.com/YOUR_USERNAME" target="_blank">
          <i class="bi bi-github"></i>
        </a> -->
      </div>
    </div>
  </header>

<!-- ======= About Section ======= -->
  <section id="about" class="about">
    <div class="container">

      <div class="section-title">
        <h2>About</h2>
      </div>

      <!-- Research Vision -->
      <div class="about-me">
        <div class="row">
          <div class="col-lg-12 content">
            <p class="fst-italic">
              We conduct research in the field of Artificial Intelligence, focusing on deep learning methodologies
              from foundational studies to practical applications, with an emphasis on perception (recognition),
              reasoning, and generative models. We aim to develop simple yet effective approaches that are easily
              understandable without complex knowledge and readily implementable without complicated algorithms,
              enabling widespread adoption.
            </p>
          </div>
        </div>

        <!-- Principal Investigator -->
        <div class="row mt-5">
          <!-- <div class="col-lg-2">
            <img src="assets/img/profile.jpg" class="img-fluid rounded" alt="Photo++">
          </div> -->
          <div class="col-lg-8 content">
            <h3>Youngsung Kim</h3>
            <h5>Assistant Professor (Tenure-track)</h5>
            <ul>
              <li><i class="bi bi-chevron-right"></i><strong>Department:</strong> Artificial Intelligence (Undergraduate); Electrical and Computer Engineering (Graduate)</li>
              <li><i class="bi bi-chevron-right"></i><strong>Institution:</strong> Inha University</li>
            </ul>

            <h4 class="mt-4">Previous Positions</h4>
            <ul>
              <li><i class="bi bi-chevron-right"></i>Principal Researcher at Samsung Advanced Institute of Technology (SAIT)</li>
              <li><i class="bi bi-chevron-right"></i>Postdoctoral Associate at SMART, MIT</li>
              <li><i class="bi bi-chevron-right"></i>Visting Researcher at MILA/SAIL & at I2R</li>
            </ul>

            <h4 class="mt-3">Education</h4>
            <ul>
              <li><i class="bi bi-chevron-right"></i>Ph.D., M.S., B.S. in Electrical and Electronic Engineering, Yonsei University</li>
            </ul>
          </div>
        </div>

        <!-- Research Team -->
        <div class="row mt-5">
          <div class="col-lg-12 content">
            <h3>Research Team</h3>
            <div class="row mt-3">
              <div class="col-md-6">
                <h5>Graduate Students</h5>
                <ul>
                  <li><i class="bi bi-person"></i> [Positions Available]</li>
                </ul>
              </div>
              <div class="col-md-6">
                <h5>Undergraduate Interns</h5>
                <ul>
                  <li><i class="bi bi-person"></i> Hanbyul Kim - Reasoning Models</li>
                  <li><i class="bi bi-person"></i> Sangmin Oh - Multimodal Models</li>
                </ul>
              </div>
            </div>
          </div>
        </div>

        <!-- Join Our Group -->
        <div class="row mt-5">
          <div class="col-lg-12">
            <div class="info-box">
              <h4><i class="bi bi-star-fill"></i> Join Our Research Group</h4>
              <p>
                We are continually seeking highly motivated undergraduate and graduate students.
                Both full-time and part-time positions are available with compensation based on qualifications.
              </p>

              <div class="row mt-3">
                <div class="col-md-6">
                  <h5>Priority Research Areas:</h5>
                  <ul>
                    <li>Multimodal Models</li>
                    <li>Visual Reasoning</li>
                    <li>Neurosymbolic AI</li>
                    <li>Deep Learning Applications</li>
                  </ul>
                </div>
                <div class="col-md-6">
                  <h5>What We Offer:</h5>
                  <ul>
                    <li>Collaborative research environment</li>
                    <li>Conference participation support</li>
                    <li>Independent research opportunities</li>
                    <li>Industry collaboration projects</li>
                  </ul>
                </div>
              </div>

              <hr style="border-color: rgba(21, 97, 109, 0.2); margin: 20px 0;">

              <h4><i class="bi bi-star-fill"></i> 연구원 모집</h4>
              <p>
                학부 및 대학원 과정에서의 열정적이고 성실한 학생들을 항상 모집합니다.
                정규(Full-time) 및 부분(Part-time) 형태 모두 가능합니다.
              </p>
              <p>
                <strong>주요 연구 분야:</strong> Multimodal Models, Visual Reasoning, Neurosymbolic AI를 포함하며,
                인공지능(AI), 머신러닝(ML) 분야의 다양한 주제를 다룰 수 있습니다.
              </p>

              <p class="text-center mt-4">
                <strong style="font-size: 18px;">Contact: y.kim@inha.ac.kr</strong>
              </p>
            </div>
          </div>
        </div>
      </div>

    </div>
  </section>

   <!-- ======= Research Interests Section ======= -->
  <section id="interests" class="interests">
    <div class="container">

      <div class="section-title">
        <h2>Research</h2>
        <p>Research Interests</p>
      </div>

      <div class="row">
        <div class="col-lg-3 col-md-4 col-sm-6">
          <div class="icon-box">
            <div class="icon-box-header">
              <div class="left">
                <i class="bi bi-cpu"></i>
                <h3>Deep Learning</h3>
              </div>
              <i class="bi bi-chevron-down toggle-icon"></i>
            </div>
            <div class="icon-box-content">
              Research focuses on neural network architectures, optimization techniques,
              and representation learning. We explore self-supervised learning and efficient
              inference methods for both small and large-scale models.
            </div>
          </div>
        </div>

        <div class="col-lg-3 col-md-4 col-sm-6">
          <div class="icon-box">
            <div class="icon-box-header">
              <div class="left">
                <i class="bi bi-gear"></i>
                <h3>Machine Learning</h3>
              </div>
              <i class="bi bi-chevron-down toggle-icon"></i>
            </div>
            <div class="icon-box-content">
              Development of novel algorithms for supervised, unsupervised, and self-supervised
              learning. Focus on interpretability and efficiency of machine learning systems.
            </div>
          </div>
        </div>

        <div class="col-lg-3 col-md-4 col-sm-6">
          <div class="icon-box">
            <div class="icon-box-header">
              <div class="left">
                <i class="bi bi-eye"></i>
                <h3>Computer Vision</h3>
              </div>
              <i class="bi bi-chevron-down toggle-icon"></i>
            </div>
            <div class="icon-box-content">
              Image and video understanding, object detection and segmentation,
              and visual scene analysis for real-world applications.
            </div>
          </div>
        </div>
        
        <!--
        <div class="col-lg-3 col-md-4 col-sm-6">
          <div class="icon-box">
            <div class="icon-box-header">
              <div class="left">
                <i class="bi bi-diagram-3"></i>
                <h3>Visual/Logical Reasoning</h3>
              </div>
              <i class="bi bi-chevron-down toggle-icon"></i>
            </div>
            <div class="icon-box-content">
              Combining visual perception with logical inference for complex reasoning tasks.
              Research on visual question answering, compositional generalization, and neurosymbolic approaches.
            </div>
          </div>
        </div>
        -->
        
        <div class="col-lg-3 col-md-4 col-sm-6 mt-4">
          <div class="icon-box">
            <div class="icon-box-header">
              <div class="left">
                <i class="bi bi-layers"></i>
                <h3>Multimodal Learning</h3>
              </div>
              <i class="bi bi-chevron-down toggle-icon"></i>
            </div>
            <div class="icon-box-content">
              Integration of multiple data modalities including vision, language, and others.
              Cross-modal retrieval, alignment, and generation with applications in human-device-AI interaction.
            </div>
          </div>
        </div>

        <div class="col-lg-3 col-md-4 col-sm-6 mt-4">
          <div class="icon-box">
            <div class="icon-box-header">
              <div class="left">
                <i class="bi bi-bezier2"></i>
                <h3>Neurosymbolic AI</h3>
              </div>
              <i class="bi bi-chevron-down toggle-icon"></i>
            </div>
            <div class="icon-box-content">
              Bridging neural networks with symbolic reasoning for interpretable and robust AI.
              Logic-guided learning, knowledge integration, and hybrid architecture design.
            </div>
          </div>
        </div>

        <div class="col-lg-3 col-md-4 col-sm-6 mt-4">
          <div class="icon-box">
            <div class="icon-box-header">
              <div class="left">
                <i class="bi bi-motherboard"></i>
                <h3>HW-SW Co-design</h3>
              </div>
              <i class="bi bi-chevron-down toggle-icon"></i>
            </div>
            <div class="icon-box-content">
              Research on hardware-software co-optimization for efficient AI systems.
              End-to-end design methodologies for accelerators, model compression, and edge deployment.
            </div>
          </div>
        </div>
      </div>


    </div>
  </section>

  <!-- ======= Publications Section ======= -->
  <section id="publications" class="resume">
    <div class="container">

      <div class="section-title">
        <h2>Publications</h2>
        <p class="subtitle">Selected Research Papers & Patents</p>
      </div>

      <div class="row">
        <div class="col-lg-12">
          <!-- Conference Papers -->
          <h3 class="resume-title">Conference Papers</h3>
          <div class="resume-item">
            <!--<h4>Conferences</h4> -->
            <ul>
              <li>
                <ptitle>Protofl: Unsupervised federated learning via prototypical distillation</ptitle><br>
                H. Kim, Y. Kwak, M. Jung, J. Shin, <strong>Y. Kim</strong>, C. Kim<br>
                <em>International Conference on Computer Vision (ICCV 2023)</em>
              </li>
              <li>
                <ptitle>Connecting Sphere Manifolds Hierarchically for Regularization</ptitle><br>
                D. Scieur*, <strong>Y. Kim</strong>* (*Equal Contribution)<br>
                <em>International Conference on Machine Learning (ICML 2021)</em>
              </li>
              <li>
                <ptitle>Few-shot Visual Reasoning with Meta-Analogical Contrastive Learning</ptitle><br>
                <strong>Y. Kim</strong>, J. Shin, E. Yang, and S. J. Hwang<br>
                <em>Neural Information Processing Systems (NeurIPS 2020)</em><br>
                <span class="text-warning">★ Samsung Best Paper Award 2021 (Silver)</span>
              </li>
              <li>
                <ptitle>Residual Encoder Decoder Network and Adaptive Prior for Face Parsing</ptitle><br>
                T. Guo, <strong>Y. Kim</strong>, H. Zhang, D. Qian, B. Yoo, J. Xu, D. Zou, J.-J. Han, and C. Choi<br>
                <em>AAAI Conference on Artificial Intelligence (AAAI 2018)</em>
              </li>
              <li>
                <ptitle>Activity Recognition for Smartphone Based Travel Surveys Based on Cross-User History Data</ptitle><br>
                <strong>Y. Kim</strong>, F. C. Pereira, F. Zhao, A. Ghorpade, P. C. Zegras, and M. Ben-Akiva<br>
                <em>International Conference on Pattern Recognition (ICPR 2014)</em>
              </li>


              <li> <ptitle>Evaluating FMS: A  preliminary comparison with a traditional travel survey</ptitle><br>
                C. Carrion, F. Pereira, R. Ball, F. Zhao, <strong>Y. Kim</strong>, K. Nawarathne, N. Zheng, C. Zegras, and M. Ben-Akiva<br>
                <em>Transportation Research Board 93rd Annual Meeting (TRB 2014)</em>
              </li>
              <li> <ptitle>An Online Learning Algorithm for Biometric Scores Fusion</ptitle><br>
                <strong>Y. Kim</strong>, K.-A. Toh, and A. B. J. Teoh<br>
                <em>The 4th IEEE Conference on Biometrics: Theory, Applications and Systems (BTAS 2010)</em>
              </li>
              <li> <ptitle>A Method to Enhance Face Biometric Security</ptitle><br>
                <strong>Y. Kim</strong> and K.-A. Toh<br>
                <em>The First IEEE Conference on Biometrics: Theory, Applications and Systems (BTAS 2007)</em>
              </li>

              </ul>
          </div>

           <!-- Journal Papers -->
          <h3 class="resume-title">Journal Papers</h3>
          <div class="resume-item">
            <!-- <h4>IEEE Publications</h4> -->
            <ul>
              <li>
                <ptitle>Deep Self-Supervised Diversity Promoting Learning on Hierarchical Hyperspheres for Regularization</ptitle><br>
                <strong>Y. Kim</strong>, Yoonsuk Hyun, Jae-Joon Han, Eunho Yang, Sung Ju Hwang, Jinwoo Shin<br>
                <em>IEEE Access, vol. 11, pp. 146208-146222, 2023</em>
              </li>
              <li>
                <ptitle>Deep stochastic logic gate networks</ptitle><br>
                <strong>Y. Kim</strong><br>
                <em>IEEE Access, vol. 11, pp. 122488-122501, 2023</em>
              </li>
              <li>
                <ptitle>Activity Recognition for a Smartphone and Web Based Human Mobility Sensing System</ptitle><br>
                <strong>Y. Kim</strong>, A. Ghorpade, F. Zhao, F. C. Pereira, P. C. Zegras, and M. Ben-Akiva<br>
                <em>IEEE Intelligent Systems, vol. 33, no. 04, pp. 5-23, 2018</em>
              </li>
              <li>
                <ptitle>Deep Facial Age Estimation using Conditional Multitask Learning with Weak Label Expansion</ptitle><br>
                B. Yoo, Y. Kwak, <strong>Y. Kim</strong>, C. Choi, and J. Kim<br>
                <em>IEEE Signal Processing Letters, vol. 25, no. 6, pp. 808-812, 2018</em>
              </li>
              <li> <ptitle>Background Subtraction Using Illumination-Invariant Structural Complexity</ptitle><br>
                      W. Kim and <strong>Y. Kim</strong><br>
                      <em>IEEE Signal Processing Letters, vol. 23, no. 5, pp. 634--638, May 2016.</em>
              </li>
              <li>
                <ptitle>Exploratory Analysis of a Smartphone-Based Travel Survey in Singapore</ptitle><br>
                F. Zhao, F. C. Pereira, R. Ball, <strong>Y. Kim</strong>, Y. Han, C. Zegras, and M. Ben-Akiva<br>
                <em>Transportation Research Record, vol. 2, no. 2494, pp. 45-56, 2015</em><br>
                <span class="text-warning">★ Pyke Johnson Award 2015 (TRB)</span>
              </li>
              

              <li> <ptitle>An Online Learning Network for Biometric Scores Fusion</ptitle><br>
                      <strong> Y. Kim</strong>, K.-A. Toh, A.B.J. Teoh, H.-L. Eng, and W.-Y. Yau<br>
                       <em>Neurocomputing, vol. 102, pp. 65-77, February 2013.</em>
              </li>
              <li> <ptitle>An Online AUC Formulation for Binary Classification</ptitle><br>
                      <strong> Y. Kim</strong>, K.-A. Toh, A.B.J. Teoh, H.-L. Eng, and W.-Y. Yau<br>
                   <em>Pattern Recognition, vol. 45, no. 6, pp. 2266-2279, June 2012.</em>
              </li>
              <li> <ptitle>A Performance Driven Methodology for Cancelable Face Templates Generation</ptitle><br>
                      <strong> Y. Kim</strong>, A.B.J. Teoh, and K.-A. Toh<br>
                   <em>Pattern Recognition, vol. 43, no. 7, pp. 2544-2559, July 2010.</em>
              </li>
              <li> <ptitle>Fusion of visual and infra-red face scores by weighted power series</ptitle><br>
                      K.-A. Toh, <strong>Y. Kim</strong>, S. Lee, and J. Kim<br>
                       <em>Pattern Recognition Letters, vol. 29, no. 5, pp. 603-615, April 2008.</em>
              </li>

            </ul>
          </div>
        </div>

        <div class="col-lg-12">
          <h3 class="resume-title">Pre-prints</h3>
          <div class="resume-item">
          <ul>
               <li><ptitle>Standard Neural Computation Alone Is Insufficient for Logical Intelligence</ptitle><br>
                        <strong>Y. Kim</strong><br>
                  <em>arXiv preprint arXiv:2502.02135</em>
                </li>
               <li><ptitle> Towards Narrowing the Generalization Gap in Deep Boolean Networks</ptitle><br>
                        <strong>Y. Kim</strong><br>
                  <em>arXiv preprint arXiv:2409.05905</em>
                </li>
                <li><ptitle>Deep hierarchical-hyperspherical learning</ptitle><br>
                        <strong>Y. Kim</strong> and J.J. Han<br>
                  <em>submitted to conference 2019</em>
                </li>
                <li><ptitle>Deep generative-contrastive networks for facial expression recognition</ptitle><br>
                        <strong>Y. Kim</strong>,  B. Yoo, Y. Kwak, C. Choi, and J. Kim<br>
                  <em>(arXiv preprint 2017, arXiv:1703.07140)</em>
                </li>
          </ul>
          </div>
        </div>

        <!-- Patents Summary -->
          <h3 class="resume-title">Intellectual Property</h3>
          <div class="resume-item">
            <h4>Patent Portfolio</h4>
            <h5>15 Registered US Patents | 7 Pending Applications</h5>
            <p>
              Our patent portfolio covers biometric authentication, facial recognition, emotion detection,
              and neural network architectures. Notable deployment includes authentication technology
              embedded in Samsung Galaxy smartphones (S6+, Note 5, S7, S8, and more).
            </p>
            <ul>
              <li><strong>Biometric Authentication:</strong> US Patents 10,248,835; 10,691,918; 10,521,642</li>
              <li><strong>Facial Recognition & Expression:</strong> US Patents 10,891,468; 10,387,716; 11,093,734</li>
              <li><strong>Neural Network Methods:</strong> US Patent Apps 17/026,951; 16/902,299</li>
            </ul>
          </div>
        </div>
      </div>

        <!-- Patents -->
         <!--
        <div class="col-lg-12">
          <h3 class="resume-title">Intellectual Property</h3>
          

          <div class="resume-item">
            <h4>Registered Patents</h4>
            <ul>
              <li>
                <ptitle>Methods and Apparatuses for Authentication Using Biometric Information</ptitle><br>
                <strong>Y. Kim</strong>, K. Kim, H. Kim, S. Suh, C. K. Choi<br>
                <em>US Patent 10,248,835</em><br>
                <span class="text-warning">★ Embedded in Samsung Galaxy Smartphones (S6+, Note 5, S7, S8, etc.)</span>
              </li>
              <li>
                <ptitle>Method and Apparatus with Expression Recognition</ptitle><br>
                <strong>Y. Kim</strong>, C. K. Choi, B. Yoo<br>
                <em>US Patent 10,891,468</em>
              </li>
              <li>
                <ptitle>Method and Apparatus for Recognizing Facial Expression</ptitle><br>
                <strong>Y. Kim</strong>, B. Yoo, Y. Kwak, C. K. Choi<br>
                <em>US Patent 10,387,716</em>
              </li>
              <li>
                <ptitle>Method and Apparatus with Emotion Recognition</ptitle><br>
                <strong>Y. Kim</strong>, Y. Kwak, B. Yoo, S. Lee<br>
                <em>US Patent 11,093,734</em>
              </li>
              <li>
                <ptitle>Method and Apparatus for Generating Facial Expression and Training Method</ptitle><br>
                <strong>Y. Kim</strong>, B. Yoo, Y. Kwak, C. K. Choi<br>
                <em>US Patent 10,621,422</em>
              </li>
              <li>
                <ptitle>Method and Apparatus for Analyzing Facial Image</ptitle><br>
                <strong>Y. Kim</strong>, B. Yoo, D. Qian, H. Zhang, C. K. Choi, H. Zheng, J.-J. Han, J. Xu, T. Guo<br>
                <em>US Patent 10,528,846</em>
              </li>
              <li>
                <ptitle>Method and Apparatus for Detecting Fake Fingerprint and Recognizing Fingerprint</ptitle><br>
                W. Kim, <strong>Y. Kim</strong>, S. Suh, H. Kim, C. K. Choi<br>
                <em>US Patent 10,691,918</em>
              </li>
              <li>
                <ptitle>Facial Verification Method and Apparatus</ptitle><br>
                B. I. Yoo, Y. Kwak, <strong>Y. Kim</strong>, J.-J Han<br>
                <em>US Patent 10,579,865</em>
              </li>
              <li>
                <ptitle>Fingerprint Verification Method and Apparatus</ptitle><br>
                S. Suh, W. Kim, <strong>Y. Kim</strong>, H. Lee<br>
                <em>US Patent 10,521,642</em>
              </li>
              <li>
                <ptitle>Method and Apparatus to Recognize Object Based on Attribute</ptitle><br>
                Y. Kwak, B. Yoo, <strong>Y. Kim</strong>, C. K. Choi<br>
                <em>US Patent 10,558,912</em>
              </li>
              <li>
                <ptitle>Method of Preprocessing Image Including Biological Information</ptitle><br>
                K. Kim, W. Kim, <strong>Y. Kim</strong>, S. Suh<br>
                <em>US Patent 10,963,668</em>
              </li>
              <li>
                <ptitle>Apparatuses and Methods for Recognizing Object and Facial Expression</ptitle><br>
                B. Yoo, Y. Kwak, <strong>Y. Kim</strong>, S. Lee<br>
                <em>US Patent 10,885,317</em>
              </li>
              <li>
                <ptitle>Liveness Test Method and Apparatus</ptitle><br>
                Y. Kwak, B. Yoo, <strong>Y. Kim</strong>, C. K. Choi, J.-J. Han<br>
                <em>US Patent 11,157,760</em>
              </li>
              <li>
                <ptitle>Liveness Test Method and Apparatus</ptitle><br>
                B. Yoo, J. Xu, C. Zhang, H. Feng, Y. Shan, Y. Kwak, <strong>Y. Kim</strong>, W. Chang, J.-J. Han<br>
                <em>US Patent 11,176,392</em>
              </li>
              <li>
                <ptitle>Device and Method for Controlling Mouse Pointer</ptitle><br>
                D.-H. Lee, M.-S. Kwon, S. Lee, K.-A. Toh, H. Lee, <strong>Y. Kim</strong>, B-S. Oh, S. Kim<br>
                <em>US Patent 8,957,857</em>
              </li>
            </ul>
          </div>

           <div class="resume-item">
            <h4>Patent Applications</h4>
            <ul>
              <li>
                <ptitle>Method and Apparatus with Neural Network Data Processing and/or Training</ptitle><br>
                <strong>Y. Kim</strong>, J.-J. Han<br>
                <em>US Patent App. 17/026,951</em>
              </li>
              <li>
                <ptitle>Neural Network Based Recognition Apparatus and Method of Training</ptitle><br>
                B. Yoo, <strong>Y. Kim</strong>, Y. Kwak, C. K. Choi<br>
                <em>US Patent App. 16/567,365</em>
              </li>
              <li>
                <ptitle>Liveness Test Method and Biometric Authentication Method</ptitle><br>
                Y. Kwak, M. Ko, <strong>Y. Kim</strong>, H. Kim, J. H. Song, B. Yoo, S. Rhee, Y.-I. Lee, J. Choi, S. J. Han<br>
                <em>US Patent App. 16/899,935</em>
              </li>
              <li>
                <ptitle>Method and Apparatus with Deep Neural Network Model Fusing</ptitle><br>
                Y. Kwak, <strong>Y. Kim</strong>, B. Yoo, Y.-I. Lee, H. Lee, S. Jung<br>
                <em>US Patent App. 16/902,299</em>
              </li>
              <li>
                <ptitle>Facial Expression Image Processing Method and Apparatus</ptitle><br>
                T. Guo, <strong>Y. Kim</strong>, H. Zhang, B. Yoo, C. K. Choi, J.-J. Han, J. Xu, D. Qian<br>
                <em>US Patent App. 17/109,762</em>
              </li>
              <li>
                <ptitle>Method and Apparatus to Determine Trigger Intent of User</ptitle><br>
                H. Zhang, T. Guo, D. Qian, X. Liu, <strong>Y. Kim</strong>, B. Yoo, J.-J. Han, C. K. Choi<br>
                <em>US Patent App. 16/243,328</em>
              </li>
              <li>
                <ptitle>Method and Apparatus to Perform Facial Expression Recognition and Training</ptitle><br>
                B. Yoo, Y. Kwak, <strong>Y. Kim</strong>, S. Rhee, C. K. Choi<br>
                <em>US Patent App. 15/626,440</em>
              </li>
            </ul>
          </div>
        </div>

      </div>   -->


    </div>
  </section>

    <!-- ======= Contact Section ======= -->
  <section id="contact" class="contact">
    <div class="container">

      <div class="section-title">
        <h2>Contact</h2>
        <p>Get in Touch</p>
      </div>

      <div class="row mt-2">
        <div class="col-md-6 d-flex align-items-stretch">
          <div class="info-box">
            <i class="bx bx-envelope"></i>
            <h3>Email</h3>
            <p>y.kim@inha.ac.kr</p>
          </div>
        </div>

        <div class="col-md-6 d-flex align-items-stretch">
          <div class="info-box">
            <i class="bx bx-map"></i>
            <h3>Office</h3>
            <p>Inha-ro 100, Michuhol-gu<br>Incheon 22212, Korea</p>
          </div>
        </div>

        <div class="col-md-6 d-flex align-items-stretch">
          <div class="info-box">
            <i class="bx bx-phone-call"></i>
            <h3>Phone</h3>
            <p>+82 32 860 9519</p>
          </div>
        </div>

        <div class="col-md-6 d-flex align-items-stretch">
          <div class="info-box">
            <i class="bx bx-share-alt"></i>
            <h3>Academic Profiles</h3>
            <div class="social-links">
              <a href="https://scholar.google.com/citations?user=A46lCAoAAAAJ&hl=en" target="_blank">
                <i class="bi bi-google"></i>
              </a>
              <a href="https://linkedin.com/in/youngsung-kim-156a4345" target="_blank">
                <i class="bi bi-linkedin"></i>
              </a>
              <!--- <a href="https://github.com/YOUR_USERNAME" target="_blank">
                <i class="bi bi-github"></i>
              </a> -->
            </div>
          </div>
        </div>
      </div>

    </div>
  </section>


  <!-- Credits -->
  <div class="credits">
    Copyright &copy; 2025 Youngsung Kim | AI Research Group<br>
    <a href="https://inha.ac.kr" target="_blank">Inha University</a>
  </div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>


</body>
</html>
